{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Milestone Project 1: Scenario 3 Overview \n",
    "\n",
    "You are the manager of a very successful bakery chain. Every few months, new items are introduced to the menu. In the past, the bakery chose to add items that could be made with whatever ingredients were leftover in the kitchen. However, you think this process could be improved upon. You recently got a hold of a dataset that shows sales records from the past few months at Kekiâ€™s bakery.\n",
    "\n",
    "Your report will provide information on the highest- and lowest-performing baked goods to persuade bakery stakeholders to adjust their inventory. Your report should also include information about the most profitable days for the bakery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#questions to ask: does location effect the type of food sold? \n",
    " my questions about the data set: the 'total sales' column does not match with the sume of the items sold in a column. Why? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "df = pd.read_csv('Bakery Sales.csv')\n",
    "\n",
    "# EDA \n",
    "df.rename(columns={'datetime': 'date of sale','total':'total sales', 'place': 'bakery name'} ,inplace=True)\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: EDA - verifying and cleaning day of sale column \n",
    "- Use 'Date of Sale' to verify that there are no mistakes or typos in 'Day of Sale'. Also make sure that there are no null values in 'Day of Sale'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Goal: compare 'Day of Sale' to 'Day of Week' to make sure they match \n",
    "Below is a test on fake data. Here is the plan:\n",
    "   1) convert 'date of sale' (which is a datetime type) to a day (string type)\n",
    "   2) compare wildcard of newly converted day to 'day of week' data \n",
    "'''\n",
    "\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "## make a fake 'day of sale' and covert it to a day name \n",
    "fake_dos = datetime.datetime.now() \n",
    "fake_day = calendar.day_name[fake_dos.weekday()]\n",
    "print(fake_day)\n",
    "type(fake_day)\n",
    "\n",
    "## make a fake day of week \n",
    "fake_dow = 'Mon' \n",
    "\n",
    "## compare \n",
    "# print(fake_dow in fake_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Goal: compare 'Day of Sale' column to 'Day of Week' column to make sure they match.\n",
    "We are using the real dataframe now, compared to the test above. \n",
    "'''\n",
    "\n",
    "import datetime \n",
    "from datetime import datetime\n",
    "import calendar \n",
    "\n",
    "## convert 'day of sale' from string to datetime type  \n",
    "df['date of sale'] = pd.to_datetime(df['date of sale'], format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "## convert datetime to the day of the week \n",
    "for row in range(len(df)):\n",
    "    date = df['date of sale'].iloc[row].day_name()\n",
    "    df['date of sale'].iloc[row]=date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Goal: compare the newly coverted day of week to 'day of week' column. If they match\n",
    "(aka Monday = Mon) there were no mistakes in recording keeping. \n",
    "'''\n",
    "\n",
    "## create a new column that holds the results of the match test belwo\n",
    "df[\"matching days\"] = None\n",
    "\n",
    "## QUESTION: should it be range(len(df)-1) or range(len(df))?\n",
    "## compare the two columns to see if they have matching days of the week \n",
    "for row in range(len(df)-1):\n",
    "    print(df['day of week'].iloc[row])\n",
    "    print(df['date of sale'].iloc[row])\n",
    "    b = df['day of week'].iloc[row] in df['date of sale'].iloc[row]\n",
    "    df[\"matching days\"].iloc[row] = b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count the number of matches\n",
    "count_matches = df['matching days'].sum()\n",
    "print(\"total matches:\", count_matches)\n",
    "\n",
    "## count the number of mismatches \n",
    "count_mismatches = abs(count_matches - len(df[\"matching days\"]))\n",
    "print(\"total mismatches:\", count_mismatches)\n",
    "\n",
    "## discover which rows are mismatches (aka where the date of sale does not match the day of week)\n",
    "df.loc[df['matching days'] == False]\n",
    "\n",
    "## It looks like row 116 is mismatched. The date of sale = Sunday, but the day of the week = Mon.\n",
    "## Because there is only 1 mismatch, I think I'll omit this row from my data. \n",
    "\n",
    "## remove single mismatched row by index value 116\n",
    "#df.drop([116], inplace = True)\n",
    "\n",
    "## discover if there are any null values\n",
    "df[df['matching days'].isna()]\n",
    "\n",
    "## It looks like rows 2420 to 2653 are completely null (all of their entries are null). I'll omit these as well.\n",
    "#df.drop(range(2420,2653), inplace = True)\n",
    "#df.drop([2653], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: EDA continued - delete redunant column 'Date of Sale'\n",
    "- 'Day of Week' and 'Date of Sale' features are redundant. Remove 'Date of Sale' because we are tasked to report information about the most profitable days for the bakery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now that I have verified the 'day of week' column is credible, I will delete the 'date of week' column \n",
    "#del df[\"date of sale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: EDA continued - delete unneccesary column 'Total Sales' \n",
    "\n",
    "- Consider removing 'Total Sales', since it's irrelavant to our question at hand. We care about the sales count of individual items, not the total items sold on a given day at a given bakery. \n",
    "- Additionally, although the information we are given says this column records total sales, I don't understand how this could be true. For example, the first row of data says that the Total Sales is 23,800. I don't understand how one bakery sell 23,800 items in a day. If this column is truly in fact the number of items sold in a day, this can't be true based on the fact that the count of every item sold totals to 4 or 5 items. If it was supposed to be total dollars made, how one bakery could make $23,800 in a day? I suppose I'll have to learn more about the field before I make this conclusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete 'Total Sales' column\n",
    "# del df[\"total sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: EDA continued - delete unneccessary and fairly empty column 'Bakery Name'\n",
    "\n",
    "We do not need 'Bakery Name' for this analysis, although it could be interesting in the future to see if location significantly alters the sale of different baked goods (or which bakeries are the highest performers, in which case we would want the previously deleted column 'Total Sales'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the percent of null bakery name entries \n",
    "# missing_names = df['bakery name'].isnull().sum()\n",
    "# percent_missing = missing_names/len(df['bakery name'])\n",
    "# print(percent_missing)\n",
    "\n",
    "## 10% of the bakery names are missing, which is not insignificant. I will delete them mainly because I don't need them for this analysis. \n",
    "# del df[\"bakery name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41faa1bd1fa245b7c406992dfb0be710af21dcaa19900cd739a3d6e9b9795cf1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
